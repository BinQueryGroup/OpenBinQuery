{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datasets import load_from_disk\n",
    "from typing import Tuple, List\n",
    "from hashlib import sha256\n",
    "from openai import OpenAI\n",
    "from loguru import logger\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import zstd\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete the output of the block above, as it will output a warning prompt containing identity information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_data(b_str):\n",
    "    return pickle.loads(zstd.decompress(b_str))\n",
    "def compress_data(obj):\n",
    "    return zstd.compress(pickle.dumps(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"secret.json\") as f:\n",
    "    secret = json.load(f)\n",
    "LLM_KEY = secret[\"LLM_KEY\"]\n",
    "LLM_URL = secret[\"LLM_URL\"]\n",
    "LLM_MODEL = secret[\"LLM_MODEL\"]\n",
    "TEMPERATURE = 1\n",
    "MAX_TOKENS = 8192\n",
    "TIMEOUT = 60\n",
    "with open(\"prompts/snippet_extract.txt\") as f:\n",
    "    SYSTEM_PROMPT = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=LLM_KEY, base_url=LLM_URL)\n",
    "def complete(user: str):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": SYSTEM_PROMPT,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user,\n",
    "                },\n",
    "            ],\n",
    "            timeout=TIMEOUT,\n",
    "            model=LLM_MODEL,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "        )\n",
    "        result = completion.choices[0].message.content\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_template(src_list):\n",
    "    result = \"\"\n",
    "    cnt = 0\n",
    "    for src_idx, src_row in enumerate(src_list):\n",
    "        if cnt > 768:\n",
    "            break\n",
    "        cnt += 1\n",
    "        result += f\"{src_idx} {src_row}\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranges(target):\n",
    "    ranges = []\n",
    "    current_range = target[\"range\"]\n",
    "    ranges.append(current_range)\n",
    "    if len(target[\"sub_snippets\"]) > 0:\n",
    "        for sub_snippet in target[\"sub_snippets\"]:\n",
    "            ranges += get_ranges(sub_snippet)\n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(s):\n",
    "    pattern = r\"```[\\w\\s]*\\n(.*?)```\"\n",
    "    match = re.search(pattern, s, re.DOTALL)\n",
    "    if match:\n",
    "        code_block = match.group(1).strip()\n",
    "        return eval(code_block)\n",
    "    else:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snippets(src):\n",
    "    def _get_snippets(src):\n",
    "        src_list = decompress_data(src)\n",
    "        user_input = f\"Here's the source code of the target program:\\n{source_template(src_list)}\\nPlease extract the snippets that are relevant to the target program.\"\n",
    "        llm_response = complete(user_input)\n",
    "        structured_result = get_json(llm_response)\n",
    "        ranges = get_ranges(structured_result)\n",
    "        return ranges\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            return _get_snippets(src)\n",
    "        except Exception as e:\n",
    "            logger.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"data/line_matched\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of our snippet extraction prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Function to set the CPU frequency for a given CPU',\n",
      " 'range': [0, 37],\n",
      " 'sub_snippets': [{'description': 'Retrieve the current CPU frequency policy',\n",
      "                   'range': [1, 2],\n",
      "                   'sub_snippets': []},\n",
      "                  {'description': 'Initialize variables and set the userspace '\n",
      "                                  'governor',\n",
      "                   'range': [3, 7],\n",
      "                   'sub_snippets': []},\n",
      "                  {'description': 'Check if the policy retrieval was '\n",
      "                                  'successful',\n",
      "                   'range': [9, 10],\n",
      "                   'sub_snippets': []},\n",
      "                  {'description': 'Ensure the CPU is using the userspace '\n",
      "                                  'governor',\n",
      "                   'range': [12, 20],\n",
      "                   'sub_snippets': [{'description': 'Compare the current '\n",
      "                                                    'governor with the '\n",
      "                                                    'userspace governor',\n",
      "                                     'range': [12, 13],\n",
      "                                     'sub_snippets': []},\n",
      "                                    {'description': 'Set the new policy to use '\n",
      "                                                    'the userspace governor',\n",
      "                                     'range': [14, 17],\n",
      "                                     'sub_snippets': []},\n",
      "                                    {'description': 'Apply the new policy and '\n",
      "                                                    'handle errors',\n",
      "                                     'range': [18, 20],\n",
      "                                     'sub_snippets': []}]},\n",
      "                  {'description': 'Prepare the file path and frequency value',\n",
      "                   'range': [23, 24],\n",
      "                   'sub_snippets': []},\n",
      "                  {'description': 'Open the frequency file and write the new '\n",
      "                                  'frequency value',\n",
      "                   'range': [26, 30],\n",
      "                   'sub_snippets': []},\n",
      "                  {'description': 'Check if the frequency write was successful',\n",
      "                   'range': [32, 33],\n",
      "                   'sub_snippets': []},\n",
      "                  {'description': 'Return success if no errors occurred',\n",
      "                   'range': [35, 36],\n",
      "                   'sub_snippets': []}]}\n"
     ]
    }
   ],
   "source": [
    "row = random.choice(ds)\n",
    "src = decompress_data(row[\"src\"])\n",
    "user_input = f\"Here's the source code of the target program:\\n{source_template(src)}\\nPlease extract the snippets that are relevant to the target program.\"\n",
    "llm_response = complete(user_input)\n",
    "structured_result = get_json(llm_response)\n",
    "pprint(structured_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x74977d5eb9c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map (num_proc=20): 100%|██████████| 100/100 [04:04<00:00,  2.45s/ examples]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 2948.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(lambda x: {\"snippets_from_llm\": get_snippets(x['src'])}, num_proc=20)\n",
    "ds.save_to_disk(\"data/llm_extract_snippets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
