{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datasets import load_from_disk\n",
    "from typing import Tuple, List\n",
    "from hashlib import sha256\n",
    "from openai import OpenAI\n",
    "from loguru import logger\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import json\n",
    "import zstd\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete the output of the block above, as it will output a warning prompt containing identity information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_data(b_str):\n",
    "    return pickle.loads(zstd.decompress(b_str))\n",
    "def compress_data(obj):\n",
    "    return zstd.compress(pickle.dumps(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"secret.json\") as f:\n",
    "    secret = json.load(f)\n",
    "LLM_KEY = secret[\"LLM_KEY\"]\n",
    "LLM_URL = secret[\"LLM_URL\"]\n",
    "LLM_MODEL = secret[\"LLM_MODEL\"]\n",
    "TEMPERATURE = 1\n",
    "MAX_TOKENS = 8192\n",
    "TIMEOUT = 60\n",
    "with open(\"prompts/text_generation.txt\") as f:\n",
    "    SYSTEM_PROMPT = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=LLM_KEY, base_url=LLM_URL)\n",
    "def complete(user: str):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": SYSTEM_PROMPT,\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user,\n",
    "                },\n",
    "            ],\n",
    "            timeout=TIMEOUT,\n",
    "            model=LLM_MODEL,\n",
    "            temperature=TEMPERATURE,\n",
    "            max_tokens=MAX_TOKENS,\n",
    "        )\n",
    "        result = completion.choices[0].message.content\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_template(src_list):\n",
    "    result = \"\"\n",
    "    cnt = 0\n",
    "    for src_idx, src_row in enumerate(src_list):\n",
    "        if cnt > 768:\n",
    "            break\n",
    "        cnt += 1\n",
    "        result += f\"{src_idx} {src_row}\\n\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(s):\n",
    "    pattern = r\"```[\\w\\s]*\\n(.*?)```\"\n",
    "    match = re.search(pattern, s, re.DOTALL)\n",
    "    if match:\n",
    "        code_block = match.group(1).strip()\n",
    "        return eval(code_block)\n",
    "    else:\n",
    "        raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_descriptions(row):\n",
    "    src_list = decompress_data(row[\"src\"])\n",
    "    llm_candidates = row[\"snippets_from_llm\"]\n",
    "    rule_candidates = row[\"snippets_from_rule\"]\n",
    "    candidates = list(set([tuple(c) for c in llm_candidates + rule_candidates]))\n",
    "    src_s = source_template(src_list)\n",
    "    user_input = \"Here's the target source function:\" + \"\\n\"\n",
    "    user_input += source_template(src_list) + \"\\n\"\n",
    "    user_input += f\"candidates: {candidates}\\n\"\n",
    "    response = complete(user_input)\n",
    "    result = get_json(response)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"data/rule_llm_extract_snippets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of text generation in both `function-level` and `snippet-level`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 int process_cddb_titles(int sock_fd, char *inbuff, int readbytes)\n",
      "1 {\n",
      "2 \tint\tfinished = 0;\n",
      "3 \tchar\t*p = inbuff;\n",
      "4 \tint\tind = 0;\n",
      "5 \tunsigned char **\ttarget = &global.creator;\n",
      "6 \n",
      "7 \tdo {\n",
      "8 \t\twhile (readbytes > 0) {\n",
      "9 \t\t\t/* do we have a complete line in the buffer? */\n",
      "10 \t\t\tp = (char *)memchr(inbuff+ind, '\\n', readbytes);\n",
      "11 \t\t\tif (p == NULL) break;\n",
      "12 \n",
      "13 \t\t\t/* look for the terminator first */\n",
      "14 \t\t\tif (!strncmp(\".\\r\\n\", inbuff+ind, 3)) {\n",
      "15 \t\t\t\tfinished = 1;\n",
      "16 \t\t\t\tbreak;\n",
      "17 \t\t\t}\n",
      "18 \t\t\t/* kill carriage return */\n",
      "19 \t\t\tif (p > inbuff+ind && *(p-1) == '\\r') {\n",
      "20 \t\t\t\t*(p-1) = '\\0';\n",
      "21 \t\t\t}\n",
      "22 \t\t\t/* kill line feed */\n",
      "23 \t\t\t*p = '\\0';\n",
      "24 \n",
      "25 \t\t\t/* handle escaped characters */\n",
      "26 \n",
      "27 \t\t\t{\n",
      "28 \t\t\t\tchar *q = inbuff+ind;\n",
      "29 \t\t\t\twhile (*q) {\n",
      "30 \t\t\t\t\tif (*q++ == '\\\\' && *q != '\\0') {\n",
      "31 \t\t\t\t\t\tif (*q == '\\\\') {\n",
      "32 \t\t\t\t\t\t\treadbytes--;\n",
      "33 \t\t\t\t\t\t\tp--;\n",
      "34 \t\t\t\t\t\t\tmemmove(q, q+1, readbytes - (q-inbuff-ind));\n",
      "35 \t\t\t\t\t\t} else if (*q == 'n') {\n",
      "36 \t\t\t\t\t\t\t*(q-1) = '\\n';\n",
      "37 \t\t\t\t\t\t\treadbytes--;\n",
      "38 \t\t\t\t\t\t\tp--;\n",
      "39 \t\t\t\t\t\t\tmemmove(q, q+1, readbytes - (q-inbuff-ind));\n",
      "40 \t\t\t\t\t\t} else if (*q == 't') {\n",
      "41 \t\t\t\t\t\t\t*(q-1) = '\\t';\n",
      "42 \t\t\t\t\t\t\treadbytes--;\n",
      "43 \t\t\t\t\t\t\tp--;\n",
      "44 \t\t\t\t\t\t\tmemmove(q, q+1, readbytes - (q-inbuff-ind));\n",
      "45 \t\t\t\t\t\t}\n",
      "46 \t\t\t\t\t}\n",
      "47 \t\t\t\t}\n",
      "48 \t\t\t\t\t\t\n",
      "49 \t\t\t}\n",
      "50 \n",
      "51 \t\t\t/* handle multi line entries concatenate fields */\n",
      "52 \n",
      "53 /* TODO if the delimiter is split into two lines, it is not recognized. */\n",
      "54 \t\t\tif (!strncmp(inbuff+ind, \"DTITLE=\", 7)) {\n",
      "55 \t\t\t\tchar *res = strstr(inbuff+ind+7, \" / \");\n",
      "56 \t\t\t\tint clen;\n",
      "57 \t\t\t\tchar *q;\n",
      "58 \n",
      "59 \t\t\t\tif (res == NULL) {\n",
      "60 \t\t\t\t\t/* no limiter found yet */\n",
      "61 \t\t\t\t\t/* copy until the end */\n",
      "62 \t\t\t\t\tq = p;\n",
      "63 \t\t\t\t} else {\n",
      "64 \t\t\t\t\t/* limiter found */\n",
      "65 \t\t\t\t\t/* copy until the limiter */\n",
      "66 \t\t\t\t\tq = res;\n",
      "67 \t\t\t\t\t*q = '\\0';\n",
      "68 \t\t\t\t}\n",
      "69 \n",
      "70 \t\t\t\tclen = q - (inbuff+ind+7);\n",
      "71 \t\t\t\tif (*target == NULL) {\n",
      "72 \t\t\t\t\t*target = malloc(clen+1);\n",
      "73 \t\t\t\t\tif (*target != NULL)\n",
      "74 \t\t\t\t\t\t**target = '\\0';\n",
      "75 \t\t\t\t} else {\n",
      "76 \t\t\t\t        *target = realloc(*target, strlen((char *)*target) + clen - 1);\n",
      "77 \t\t\t\t}\n",
      "78 \t\t\t\tif (*target != NULL) {\n",
      "79 \t\t\t\t\tstrcat((char *)*target, inbuff+ind+7);\n",
      "80 \t\t\t\t}\n",
      "81 \n",
      "82 \t\t\t\t/* handle part after the delimiter, if present */\n",
      "83 \t\t\t\tif (res != NULL) {\n",
      "84 \t\t\t\t\ttarget = (unsigned char **)&global.disctitle;\n",
      "85 \t\t\t\t\t/* skip the delimiter */\n",
      "86 \t\t\t\t\tq += 3;\n",
      "87 \t\t\t\t\tclen = p - q;\n",
      "88 \t\t\t\t\tif (*target == NULL) {\n",
      "89 \t\t\t\t\t\t*target = malloc(clen+1);\n",
      "90 \t\t\t\t\t\tif (*target != NULL)\n",
      "91 \t\t\t\t\t\t\t**target = '\\0';\n",
      "92 \t\t\t\t\t}\n",
      "93 \t\t\t\t\tif (*target != NULL) {\n",
      "94 \t\t\t\t\t\tstrcat((char *)*target, q);\n",
      "95 \t\t\t\t\t}\n",
      "96 \t\t\t\t}\n",
      "97 \t\t\t} else if (!strncmp(inbuff+ind, \"TTITLE\", 6)) {\n",
      "98 \t\t\t\tchar\t*q = (char *)memchr(inbuff+ind, '=', readbytes);\n",
      "99 \t\t\t\tunsigned tno;\n",
      "100 \n",
      "101 \t\t\t\tif (q != NULL) {\n",
      "102 \t\t\t\t\t*q = '\\0';\n",
      "103 \t\t\t\t\ttno = (unsigned)atoi(inbuff+ind+6);\n",
      "104 \t\t\t\t\ttno++;\n",
      "105 \t\t\t\t\tif (tno < 100) {\n",
      "106 \t\t\t\t\t\tif (global.tracktitle[tno] == NULL) {\n",
      "107 \t\t\t\t\t\t\tglobal.tracktitle[tno] = malloc( p - q + 1 );\n",
      "108 \t\t\t\t\t\t\tif (global.tracktitle[tno] != NULL)\n",
      "109 \t\t\t\t\t\t\t\t*(global.tracktitle[tno]) = '\\0';\n",
      "110 \t\t\t\t\t\t} else {\n",
      "111 \t\t\t\t\t\t\tglobal.tracktitle[tno] = realloc(global.tracktitle[tno], strlen((char *)global.tracktitle[tno]) + p - q + 1 );\n",
      "112 \t\t\t\t\t\t}\n",
      "113 \t\t\t\t\t\tif (global.tracktitle[tno] != NULL) {\n",
      "114 \t\t\t\t\t\t\tstrcat((char *)global.tracktitle[tno], q+1);\n",
      "115 \t\t\t\t\t\t}\n",
      "116 \t\t\t\t\t}\n",
      "117 \t\t\t\t}\n",
      "118 \t\t\t} else if (!strncmp(inbuff+ind, \"DYEAR\", 5)) {\n",
      "119 \t\t\t\tchar\t*q = (char *)memchr(inbuff+ind, '=', readbytes);\n",
      "120 \t\t\t\tif (q++ != NULL) {\n",
      "121 \t\t\t\t\tsscanf(q, \"%d\", &global.cddb_year);\n",
      "122 \t\t\t\t}\n",
      "123 \t\t\t} else if (!strncmp(inbuff+ind, \"DGENRE\", 6)) {\n",
      "124 \t\t\t\tchar\t*q = (char *)memchr(inbuff+ind, '=', readbytes);\n",
      "125 \t\t\t\tif (q++ != NULL) {\n",
      "126 \t\t\t\t\t/* patch from Joe Nuzman, thanks */\n",
      "127 \t\t\t\t\t/* might have significant whitespace */\n",
      "128 \t\t\t\t\tstrncpy(global.cddb_genre, q, sizeof(global.cddb_genre)-1);\n",
      "129 \t\t\t\t\t/* always have a terminator */\n",
      "130 \t\t\t\t\tglobal.cddb_genre[sizeof(global.cddb_genre)-1] = '\\0';\n",
      "131 \t\t\t\t}\n",
      "132 \t\t\t} else if (!strncmp(inbuff+ind, \"# Revision: \", 12)) {\n",
      "133 \t\t\t\tchar\t*q = inbuff+ind+11;\n",
      "134 \t\t\t\tsscanf(q, \"%d\", &global.cddb_revision);\n",
      "135 \t\t\t\tglobal.cddb_revision++;\n",
      "136 \t\t\t}\n",
      "137 \t\t\treadbytes -= (p - inbuff -ind) + 1;\n",
      "138 \t\t\tind = (p - inbuff) + 1;\n",
      "139 \t\t}\n",
      "140 \t\tif (!finished) {\n",
      "141 \t\t\tint\tnewbytes;\n",
      "142 \t\t\tmemmove(inbuff, inbuff+ind, readbytes);\n",
      "143 \t\t\tnewbytes = readn(sock_fd, inbuff+readbytes, SOCKBUFF-readbytes);\n",
      "144 \t\t\tif (newbytes < 0) {\n",
      "145 \t\t\t\tfprintf(stderr, \"Could not read from socket.\\n\");\n",
      "146 \t\t\t\treturn 0; /* Caller checks for != 1 */\n",
      "147 \t\t\t}\n",
      "148 \t\t\tfilter_nonprintable(inbuff+readbytes, newbytes);\n",
      "149 \t\t\tif (newbytes <= 0)\n",
      "150 \t\t\t\tbreak;\n",
      "151 \t\t\treadbytes += newbytes;\n",
      "152 \t\t\tind = 0;\n",
      "153 \t\t}\n",
      "154 \t} while (!(finished || readbytes == 0));\n",
      "155 \treturn finished;\n",
      "156 }\n",
      "157 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = random.choice(ds)\n",
    "print(source_template(decompress_data(row[\"src\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function_description': {'functionality': 'Process and parse CDDB (Compact '\n",
      "                                           'Disc Data Base) titles from a '\n",
      "                                           'buffer, handling various metadata '\n",
      "                                           'fields such as disc titles, track '\n",
      "                                           'titles, release years, and genres. '\n",
      "                                           'The function reads data from a '\n",
      "                                           'socket, processes it line by line, '\n",
      "                                           'and updates global variables with '\n",
      "                                           'the parsed information.',\n",
      "                          'implementation': 'The function iteratively reads '\n",
      "                                            'data from a buffer, checks for '\n",
      "                                            'complete lines, and processes '\n",
      "                                            'each line based on predefined '\n",
      "                                            \"patterns (e.g., 'DTITLE=', \"\n",
      "                                            \"'TTITLE', 'DYEAR', 'DGENRE'). It \"\n",
      "                                            'handles escaped characters, '\n",
      "                                            'concatenates multi-line entries, '\n",
      "                                            'and dynamically allocates memory '\n",
      "                                            'to store the parsed data. The '\n",
      "                                            'function also manages incomplete '\n",
      "                                            'data by moving unprocessed bytes '\n",
      "                                            'to the beginning of the buffer '\n",
      "                                            'and reading additional data from '\n",
      "                                            'the socket until a termination '\n",
      "                                            'condition is met.',\n",
      "                          'labels': ['CDDB Parsing',\n",
      "                                     'Buffer Processing',\n",
      "                                     'Socket Communication',\n",
      "                                     'Memory Management']},\n",
      " 'snippet_descriptions': {(27, 50): [{'description': 'Process lines of text '\n",
      "                                                     'from a buffer, handling '\n",
      "                                                     'escaped characters and '\n",
      "                                                     'concatenating multi-line '\n",
      "                                                     'entries. This ensures '\n",
      "                                                     'that the data is '\n",
      "                                                     'correctly formatted and '\n",
      "                                                     'ready for further '\n",
      "                                                     'processing, maintaining '\n",
      "                                                     'the integrity of the '\n",
      "                                                     'original information.',\n",
      "                                      'role': 'architect'},\n",
      "                                     {'description': 'Use nested loops to '\n",
      "                                                     'iterate through the '\n",
      "                                                     'buffer, identifying and '\n",
      "                                                     'processing escaped '\n",
      "                                                     \"characters (e.g., '\\\\', \"\n",
      "                                                     \"'n', 't'). Adjust the \"\n",
      "                                                     'buffer size and move '\n",
      "                                                     'data to handle these '\n",
      "                                                     'characters correctly. '\n",
      "                                                     'Concatenate multi-line '\n",
      "                                                     'entries to form complete '\n",
      "                                                     'fields, ensuring that '\n",
      "                                                     'the data is correctly '\n",
      "                                                     'parsed and stored.',\n",
      "                                      'role': 'developer'},\n",
      "                                     {'description': 'Implement a nested '\n",
      "                                                     'control structure to '\n",
      "                                                     'process each character '\n",
      "                                                     'in a sequence, checking '\n",
      "                                                     'for specific escape '\n",
      "                                                     'sequences and adjusting '\n",
      "                                                     'the data accordingly. '\n",
      "                                                     'This pattern of '\n",
      "                                                     'sequential data '\n",
      "                                                     'processing and '\n",
      "                                                     'conditional adjustments '\n",
      "                                                     'is common in compiled '\n",
      "                                                     'code that handles text '\n",
      "                                                     'parsing and formatting.',\n",
      "                                      'role': 'reverse_engineer'}],\n",
      "                          (54, 98): [{'description': 'Parse and store '\n",
      "                                                     'different types of '\n",
      "                                                     'metadata fields (e.g., '\n",
      "                                                     'disc titles, track '\n",
      "                                                     'titles) from the buffer. '\n",
      "                                                     'This ensures that the '\n",
      "                                                     'relevant information is '\n",
      "                                                     'extracted and stored in '\n",
      "                                                     'appropriate global '\n",
      "                                                     'variables, ready for use '\n",
      "                                                     'in other parts of the '\n",
      "                                                     'program.',\n",
      "                                      'role': 'architect'},\n",
      "                                     {'description': 'Use conditional '\n",
      "                                                     'statements to identify '\n",
      "                                                     'specific patterns in the '\n",
      "                                                     \"buffer (e.g., 'DTITLE=', \"\n",
      "                                                     \"'TTITLE'). Extract the \"\n",
      "                                                     'relevant data, '\n",
      "                                                     'dynamically allocate '\n",
      "                                                     'memory to store it, and '\n",
      "                                                     'concatenate multi-line '\n",
      "                                                     'entries. This ensures '\n",
      "                                                     'that the metadata is '\n",
      "                                                     'correctly parsed and '\n",
      "                                                     'stored for further use.',\n",
      "                                      'role': 'developer'},\n",
      "                                     {'description': 'Implement conditional '\n",
      "                                                     'checks to identify '\n",
      "                                                     'specific patterns in the '\n",
      "                                                     'data, followed by '\n",
      "                                                     'dynamic memory '\n",
      "                                                     'allocation and string '\n",
      "                                                     'concatenation. This '\n",
      "                                                     'pattern is indicative of '\n",
      "                                                     'compiled code that '\n",
      "                                                     'handles structured data '\n",
      "                                                     'parsing and storage, '\n",
      "                                                     'common in applications '\n",
      "                                                     'that process metadata or '\n",
      "                                                     'configuration files.',\n",
      "                                      'role': 'reverse_engineer'}],\n",
      "                          (140, 154): [{'description': 'Manage incomplete data '\n",
      "                                                       'by moving unprocessed '\n",
      "                                                       'bytes to the beginning '\n",
      "                                                       'of the buffer and '\n",
      "                                                       'reading additional '\n",
      "                                                       'data from the socket. '\n",
      "                                                       'This ensures that the '\n",
      "                                                       'function can handle '\n",
      "                                                       'large or fragmented '\n",
      "                                                       'data streams, '\n",
      "                                                       'maintaining the '\n",
      "                                                       'integrity of the data '\n",
      "                                                       'processing.',\n",
      "                                        'role': 'architect'},\n",
      "                                       {'description': 'Use a loop to handle '\n",
      "                                                       'incomplete data, '\n",
      "                                                       'moving unprocessed '\n",
      "                                                       'bytes to the start of '\n",
      "                                                       'the buffer and reading '\n",
      "                                                       'more data from the '\n",
      "                                                       'socket. This ensures '\n",
      "                                                       'that the function can '\n",
      "                                                       'continue processing '\n",
      "                                                       'until all data is read '\n",
      "                                                       'or a termination '\n",
      "                                                       'condition is met, '\n",
      "                                                       'handling potential '\n",
      "                                                       'issues with fragmented '\n",
      "                                                       'data streams.',\n",
      "                                        'role': 'developer'},\n",
      "                                       {'description': 'Implement a loop to '\n",
      "                                                       'manage data '\n",
      "                                                       'processing, moving '\n",
      "                                                       'unprocessed data and '\n",
      "                                                       'reading additional '\n",
      "                                                       'bytes from a source. '\n",
      "                                                       'This pattern is common '\n",
      "                                                       'in compiled code that '\n",
      "                                                       'handles data streams, '\n",
      "                                                       'ensuring that the '\n",
      "                                                       'program can handle '\n",
      "                                                       'incomplete or '\n",
      "                                                       'fragmented data '\n",
      "                                                       'effectively.',\n",
      "                                        'role': 'reverse_engineer'}]}}\n"
     ]
    }
   ],
   "source": [
    "result = generate_descriptions(row)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function <lambda> at 0x7b9890d039c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map (num_proc=25): 100%|██████████| 100/100 [03:02<00:00,  1.82s/ examples]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 3380.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = ds.map(lambda x: {\"description\": compress_data(generate_descriptions(x))}, num_proc=25)\n",
    "ds.save_to_disk(\"data/function_snippets_with_descriptions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
